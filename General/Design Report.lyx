#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\begin_preamble
\date{}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\language british
\language_package default
\inputencoding auto
\fontencoding global
\font_roman times
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family rmdefault
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 2cm
\rightmargin 2cm
\bottommargin 2cm
\headheight 2cm
\headsep 2cm
\footskip 1cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip bigskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Camera-to-Camera Tracking for Person Re-identification within Thermal Imagery
\end_layout

\begin_layout Author
\noindent
Thomas Robson - hzwr87 
\end_layout

\begin_layout Date
\noindent
Submitted as part of the degree of MEng Computer Science to the Board of
 Examiners in the School of Engineering and Computing Sciences, Durham Universit
y
\end_layout

\begin_layout Abstract

\series bold
Context/Background
\end_layout

\begin_layout Abstract
Although use of thermal imagery currently poses significant advantages for
 24/7 surveillance in terms of the visibility of human, animal and vehicle
 targets under all environmental conditions, a key limitation is the lack
 of colour.
 Many current approaches to the problem of cross-camera person Re-Identification
, or the camera-to-camera tracking of pedestrian targets rely on colour
 features.
 Cross-camera person Re-Identification is a key research problem within
 the domain of visual surveillance and a key challenge for the future deployment
 of thermal sensing as an autonomous sensor technology.
 
\end_layout

\begin_layout Abstract

\series bold
Aims
\end_layout

\begin_layout Abstract
The aim of this project is to develop a system that would build upon and
 extend the range of existing thermal image detection, tracking and classificati
on approaches being carried out by the Durham University research team.
 The first step for this would be to draw upon existing work to be able
 to detect a person within thermal video imagery in real time, distinguish
 a person from other objects and track a person moving through a scene in
 real time.
 We would then implement 2-3 features/attributes from the literature studied.
 We would then carry out a first pass or initial framework for Re-Identification
 using these features/attributes.
 The system must be able to re-identify 5+ people within a test video sequence
 in real time using multiple cameras.
 This would then be extended by implementing 2 more advanced state of the
 art features/attributes and extending the Re-Identification ability to
 10+ people.
\end_layout

\begin_layout Abstract

\series bold
Method
\end_layout

\begin_layout Abstract
This system will be implemented in C++ using the OpenCV library.
 The first stage is real time person detection, which is done using MoG
 Background Subtraction, HOG person detection and a 6 dimensional Kalman
 filter per person, to store position, velocity and bounding box dimensions.
 From here, each of these people when first identified have some of their
 features stored.
 The basic features used will be height of the person, the histogram of
 thermal intensity and the thermal correlogram.
 
\color red
From here, more advanced features will be implemented.
 
\end_layout

\begin_layout Abstract

\series bold
Proposed Solution 
\end_layout

\begin_layout Abstract
The solution will take in video feeds from multiple cameras, and concurrently
 run the person detection and Re-Identification on these.
 All of these will shared the same set of previously identifies targets,
 to facilitate the identification of targets previously seen by different
 cameras.
 All previous positions for each person will be recorded and we will be
 able to estimate the pattern of movement for each target across the entire
 area covered by the cameras.
\end_layout

\begin_layout Abstract
\begin_inset VSpace bigskip
\end_inset


\end_layout

\begin_layout Abstract

\series bold
Keywords: 
\series default
Computer Vision, Re-Identification, Person Tracking, Features, Attributes,
 Thermal Imagery
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Abstract
These instructions give you guidelines for preparing the design paper.
 DO NOT change any settings, such as margins and font sizes.
 Just use this as a template and modify the contents into your design paper.
 Do not cite references in the abstract.
\end_layout

\begin_layout Abstract
The abstract must be a Structured Abstract with the headings 
\series bold
Context/Background
\series default
, 
\series bold
Aims
\series default
, 
\series bold
Method
\series default
, and 
\series bold
Proposed Solution
\series default
.
 This section should not be no longer than a page, and having no more than
 two or three sentences under each heading is advised.
 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Introduction
\end_layout

\begin_layout Standard
A fundamental task for a distributed multi-camera surveillance system is
 to associate people across different camera views at different locations
 and times 
\begin_inset CommandInset citation
LatexCommand cite
key "Gong2014"

\end_inset

.
 This is referred to as the Person Re-Identification problem 
\begin_inset CommandInset citation
LatexCommand cite
key "Gong2014"

\end_inset

 and is an interesting and important problem within the field of computer
 vision, with many different approaches being taken to try and perform this
 process efficiently and reliably, mainly revolving around the use of features
 or attributes of a person 
\begin_inset CommandInset citation
LatexCommand cite
key "Layne"

\end_inset

.
 This has been researched widely in colour space, but there has been very
 little research done on solving this problem in thermal space.
 
\end_layout

\begin_layout Standard
There are many potential applications for this technology, but the most
 important in the modern world would be to support human intelligence organisati
ons.
 The surveillance data that a system like this can provide would be critical
 for crime-prevention, forensic analysis, and counter-terrorism activities
 in both civilian and governmental agencies alike.
 While this is widely used by human operators, these operators have to be
 trained, which offsets the utility of this approach with training and staffing
 costs.
 The implementation of an automated Re-Identification system is therefore
 of great interest, as it would be very useful in supporting these human
 operators and enabling them to achieve better results more efficiently.
 This would be particularly important in thermal space, as many of the features
 that we propose to use are complex and mathematically grounded, making
 them difficult for a human analyst to observe.
\end_layout

\begin_layout Standard
From the previous work that we have studied, we can see that a substantial
 amount of research that has been done on Person Re-Identification, but
 much of this relies on the colour spectrum, with attributes of the form
 “red shirt” 
\begin_inset CommandInset citation
LatexCommand cite
key "Layne"

\end_inset

.
 However, in the modern world, thermal imagery is often used for 24/7 surveillan
ce when all environmental conditions are possible.
 Therefore, it is important that an effective Re-Identification system is
 developed to utilise this area of surveillance.
 Whilst thermal imagery has many advantages, it is not able to identify
 colour, making attributes that rely on colour useless.
 Therefore, alternative features are required to facilitate Re-Identification.
 Recently there has been an increase in the amount of research into thermal
 tracking, and some focus on Re-Identification, although mainly in robotics,
 rather than in a distributed camera network, as discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Konigs2013"

\end_inset

 and 
\begin_inset CommandInset citation
LatexCommand cite
key "Ciric2013"

\end_inset

.
\end_layout

\begin_layout Standard
The intent of this project is to expand upon this existing research and
 answer the question 
\series bold

\begin_inset Quotes eld
\end_inset


\series default
Which features of a human target are appropriate to facilitate Re-Identification
 in thermal video?
\series bold

\begin_inset Quotes erd
\end_inset

.
 
\series default
The challenges associated with answering this question are mostly due to
 the increased complexity of the features required in thermal space, as
 we do not have simple colour features available to us.
 Such features, as described in more detail in 
\begin_inset CommandInset citation
LatexCommand cite
key "Layne"

\end_inset

, have many applications from clothes colour to hair and skin colour.
 In thermal, we cannot use such simple features, so must think in a more
 complex way.
 The closest we can get to colour in thermal is intensity, so a histogram
 of these intensities per target will be a key feature for us to use.
 We also draw inspiration from 
\begin_inset CommandInset citation
LatexCommand cite
key "Huang,Zhang2015"

\end_inset

, which suggest the use of a colour correlogram.
 This method gives an idea of spatial correlation of colours, using a table
 indexed by colour pairs, where the k-th entry for <i, j> specifies the
 probability of finding a pixel of colour j at a distance k from a pixel
 of colour i in the image.
 We will apply a similar principle to thermal intensity values in this project.
 
\series bold
NOW TALK ABOUT HEIGHT AND ADVANCED FEATURES.
\end_layout

\begin_layout Standard
When considering a network or multiple cameras, it is important to consider
 the layout, or topology of these cameras.
 This enables us to take more meaning from the data that the system will
 give us, and determine estimated paths that the targets follow when they
 are out of view of the cameras.
 When the camera system that we will use is set up, we will note down coordinate
s of each camera's position, and overlay these on an area map.
 From here, once the system has tracked some people and recorder some data,
 we will plot the movements of each target on this map.
 
\end_layout

\begin_layout Subsection
Aims of the Project
\end_layout

\begin_layout Standard
The aim of this project is to investigate the above research question by
 developing a system that can detect a person within thermal video imagery
 in real time, distinguish this person from other objects in the scene and
 track this person moving through a scene in real time.
 We would then implement 2-3 features/attributes, and use these to carry
 out a first pass or initial framework for Re-Identification.
 At this stage, the system must be able to Re-Identify at least 5 people
 within a test video sequence in real time using multiple cameras.
 This would then be extended by implementing 2 more advanced state of the
 art features/attributes and extending the Re-Identification ability to
 at least 10 people.
\end_layout

\begin_layout Subsection
Deliverables
\end_layout

\begin_layout Subsubsection
Basic Deliverables
\end_layout

\begin_layout Enumerate
Ability to detect a person within thermal video imagery in real time.
 
\end_layout

\begin_layout Enumerate
Ability to distinguish a person from other objects.
 
\end_layout

\begin_layout Enumerate
Ability to track a person moving through a scene in real time.
\end_layout

\begin_layout Subsubsection
Intermediate Deliverables
\end_layout

\begin_layout Enumerate
Implement 2-3 state of the art features/attributes for Re-Identification.
\end_layout

\begin_layout Enumerate
First pass/Initial framework for Re-Identification using these features/attribut
es.
 
\end_layout

\begin_layout Enumerate
Ability to re-identify at least people within a test video sequence in real
 time using multiple cameras.
\end_layout

\begin_layout Subsubsection
Advanced Deliverables
\end_layout

\begin_layout Enumerate
Extend this by implementing 2 more state of the art features/attributes.
 
\end_layout

\begin_layout Enumerate
Extend the Re-Identification ability to at least 10 people.
\end_layout

\begin_layout Section
Design
\end_layout

\begin_layout Subsection
Requirements
\end_layout

\begin_layout Standard
Here we list all of the Functional and Non-Functional Requirements of the
 proposed system, presented in two tables below.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="11" columns="2">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Requirement Number
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Description
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Be able to track a human target in thermal video.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR1.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Perform effective background subtraction and foreground target identification.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR1.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Perform person detection based on foreground objects identified in FR1.1.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR1.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Be able to track distinct targets and predict their next position using
 a Kalman Filter.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Be able to Re-Identify people based on basic features.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR2.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Be able to determine the height of a person and compare this to identified
 targets.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR2.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Be able to build up a histogram of thermal intensities of a target and compare
 to identified targets.
 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR2.3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Be able to build up a correlogram of thermal intensities of a target and
 compare to identified targets.
 
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Be able to Re-Identify people based on advanced features.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
FR3.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
MORE WHEN DECIDED ON ADVANCED FEATURES
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Functional Requirements
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="2">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Requirement Number
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Description
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
NFR1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
The system shall run in as close as possible to real-time.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
NFR2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
The system must be able to run on multiple cameras, or video files, simultaneous
ly.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
NFR3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
The code must be well documented, understandable and efficient
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Non-Functional Requirements
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Implementation
\end_layout

\begin_layout Standard
Here we give details of the structure of the implementation, the tools used
 in its development and the process employed.
\end_layout

\begin_layout Subsubsection
Code Structure
\end_layout

\begin_layout Standard
The implementation will begin by opening each video file, or camera, and
 concurrently running the real time target detection code on these.
 When this code identifies a target, it compares it to the other targets
 that have been seen previously, and if it is deemed to be sufficiently
 similar to a previous target, then this target is re-identified, else it
 creates a new target.
 Each of these has an associated Kalman Feature position estimator and a
 set of features, and these are used to facilitate the comparison between
 targets.
 
\end_layout

\begin_layout Subsubsection
Tools Used
\end_layout

\begin_layout Standard
Many of the computer vision techniques that will be described in the next
 section are complex to implement.
 Therefore, the OpenCV library 
\begin_inset CommandInset citation
LatexCommand cite
key "opencv_library"

\end_inset

 has been used to allow us to use stable, well tested code, giving confidence
 in the results obtained while enabling us to focus on the research and
 implementation of the features, which is the main purpose of this project.
 This library provides all of the the image processing and machine learning
 techniques to facilitate the first stage of this project.
 The implementation will be developed in C++ as it is the most suitable
 for the performance requirements and has a well supported implementation
 of OpenCV functions.
 A text editor will be used for code development and CMake will be used
 for building and deployment of the system, while GitHub has been used for
 backups and version control.
\end_layout

\begin_layout Subsubsection
Development Process
\end_layout

\begin_layout Standard
For the development of this system, agile development methods have been
 applied to this single person project.
 The weekly meetings held with the supervisor have functioned as stand-up
 meetings would in a group based agile development process, while scrum
 methodologies have been applied to development of individual components
 of the system, functioning as sprints.
 This has proven to be an effective way of organising the development of
 this system.
\end_layout

\begin_layout Subsection
Real Time Target Detection
\end_layout

\begin_layout Standard
Before we can start concerning ourselves with feature based person Re-Identifica
tion, we must be able to identify whether a person is present in the image
 at all.
 This requires several stages, background subtraction, person identification
 and person tracking with position prediction.
\end_layout

\begin_layout Subsubsection
Background Subtraction
\end_layout

\begin_layout Standard
The first stage of this process is background subtraction, addressing FR1.1.
 We use the Mixture of Gaussians (MoG) technique to facilitate this, taking
 inspiration from 
\begin_inset CommandInset citation
LatexCommand cite
key "Zivkovic2004,Zivkovic"

\end_inset

.
 This technique works by building up a background model, modelling each
 of the pixels by multiple Gaussians.
 Using a Gaussian over the last N frames, where N is given by a parameter
 specifying the rate at which the background model is updated, is far more
 memory efficient than storing all of the pixel values across the entire
 video capture.
 During each new frame, a Gaussian for each pixel is evaluated using a simple
 heuristic to determine which is most likely to correspond to the background
 model.
 Pixels that do not match with these background Gaussians are classified
 as foreground.
 Once these foreground pixels are identified, erosion and dilation are used
 to clean up these results.
 From here, we use contour detection to find the connected components, and
 draw bounding boxes around these contours.
 Figure 1 below shows the background model that the system has built up,
 the foreground of the image, the target identified and the bounding box
 associated with this target, taken from one frame of an example video used
 for testing.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/tom/Pictures/Mog
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
MoG Background Subtraction Output
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Person Identification
\end_layout

\begin_layout Standard
Having identified the foreground objects, we must now determine whether
 they are people, addressing FR1.2.
 This implementation has two options for this, the first of these is using
 Histogram of Oriented Gradients (HOG), discussed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Dalal"

\end_inset

.
 This method works by performing edge detection on the bounding box identified
 by the background subtraction, and calculating the gradient and magnitude
 of each of these edges.
 From here cell histograms are computed, with each of the histogram entries
 filled by gradient magnitudes.
 These histograms are then used to create overlapping block histograms of
 the adjacent cells.
 These block histograms are then combined to give a HOG descriptor, a high
 dimensional vector.
 This HOG descriptor is then passed to a pre-trained Machine Learning algorithm,
 in this case a Support Vector Machine (SVM).
 If this comes up with a positive identification, then it is classified
 as a person.
 
\end_layout

\begin_layout Standard
An alternative to HOG is the use of a Haar Cascade detector, proposed in
 
\begin_inset CommandInset citation
LatexCommand cite
key "RainerLienhartandJochenMaydt2002,Viola"

\end_inset

.
 This method works by combining successively more complex classifiers in
 a cascade structure.
 This focuses the attention of the detector on the promising reasons of
 the image.
 It is trained on a set of very simple features, which are much faster to
 evaluate than the HOG descriptors.
 The final classification is done using a combination of these classifiers
 in a cascade structure, beginning with those less accurate but faster classifie
rs to discard clearly negative areas.
 
\end_layout

\begin_layout Standard
The reason for the inclusion of both methods here is that there is a trade
 off between them.
 HOG is a slightly more accurate identifier, but it is slow, even within
 the confines of the bounding box identified.
 The Haar Cascade is much faster, but gets a slightly inferior classification
 rate.
 For this reason, the option exists to change between the two systems, depending
 on whether speed or accuracy is important, or how much emphasis is put
 on NFR1.
 A real world example of this trade-off would be in a surveillance system,
 if the operator is looking to Re-Identify people from live video input
 they would use the Haar Cascade, but if they waned to Re-Identify people
 from pre-recorded video footage, they would use HOG.
 The output of both systems looks much the same, and is displayed in Figure
 2, where the red box represents the search area given by the background
 subtractor with additional padding, and the green box represents the identified
 human target from HOG or Haar Cascade.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/tom/Pictures/Hog
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Person Detection Output
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Person Tracking and Position Prediction
\end_layout

\begin_layout Standard
Once the target has been identified as a person, we need to track each identifie
d person, and address FR1.3.
 This is done by creating a person object for each newly identified target,
 each with an associated Kalman Filter, explained in 
\begin_inset CommandInset citation
LatexCommand cite
key "Bishop"

\end_inset

.
 A Kalman Filter is a commonly used position estimator in such tracking
 problems, and is important because it makes use of current information
 about a target to reduce the search space required in subsequent frames.
 The one used here is 6-dimensional, storing the coordinates of the centre
 of the target, its velocity in each direction and the width and height
 of the associated bounding box.
 This is updated each time the target is detected and the implementation
 then calculates a predicted position for the target in the next frame of
 the video.
 This prediction is based on a transition matrix, which in this implementation
 keeps the velocity and bounding box dimensions the same as in the current
 state, and changes the position in both x and y by adding the current velocity,
 as this is how much its position should change in the next position if
 the velocity doesn't change.
 
\end_layout

\begin_layout Standard
With such a Kalman Filter associated with each person object, we know where
 each person is positioned within the distributed camera network.
 This can inform us as to which person any identified target is likely to
 be, due to their most recent position, and can speed up the computation
 time involved in the comparison, as we know people cannot be in two places
 at once.
 Figure 3 shows the output of this, with the red box showing the area identified
 as a foreground target, and the blue box is the predicted position of the
 target in the next frame.
 The green box from the person identification phase is omitted here to reduce
 the clutter in the image, but the process is still being performed to give
 us the measurement of the target's position in each frame.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename /home/tom/Pictures/Kalman
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Caption Standard

\begin_layout Plain Layout
Kalman Filter Output
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Features for Re-Identification
\end_layout

\begin_layout Standard
To properly associate and compare person objects, we must now look at the
 thermal features of each person.
\end_layout

\begin_layout Subsubsection
Height
\end_layout

\begin_layout Subsubsection
Histogram of Thermal Intensities
\end_layout

\begin_layout Standard
The next feature that will be used is the histogram of thermal intensities.
 This will be done by first using edge detection methods to get just the
 pixels that represent the target from within the Kalman bounding box.
 From here, the intensity of each pixel that makes up the target will be
 recorded, and a histogram will be constructed of all pixels within certain
 bounds.
 
\series bold
PICK BOUNDS!! 
\series default
Each time a comparison is made, it will build up a histogram for the new
 target, and if it is sufficiently close to an existing target, then this
 feature will be satisfied.
 
\end_layout

\begin_layout Subsubsection
Thermal Correlogram
\end_layout

\begin_layout Standard
For this feature, we draw inspiration from 
\begin_inset CommandInset citation
LatexCommand cite
key "Huang,Zhang2015"

\end_inset

, which suggest the use of a colour correlogram.
 This method gives an idea of spatial correlation of colours, using a table
 indexed by colour pairs, where the k-th entry for <i, j> specifies the
 probability of finding a pixel of colour j at a distance k from a pixel
 of colour i in the image.
 We will apply a similar principle to thermal intensity values in this project.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Main Text
\end_layout

\begin_layout Plain Layout
The font used for the main text should be Times New Roman (Times) and the
 font size should be 12.
 The first line of all paragraphs should be indented by 0.25in, except for
 the first paragraph of each section, subsection, subsubsection etc.
 (the paragraph immediately after the header) where no indentation is needed.
\end_layout

\begin_layout Plain Layout
Figures and Tables
\end_layout

\begin_layout Plain Layout
In general, figures and tables should not appear before they are cited.
 Place figure captions below the figures; place table titles above the tables.
 If your figure has two parts, for example, include the labels 
\begin_inset Quotes eld
\end_inset

(a)
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

(b)
\begin_inset Quotes erd
\end_inset

 as part of the artwork.
 Please verify that figures and tables you mention in the text actually
 exist.
 make sure that all tables and figures are numbered as shown in Table
\end_layout

\begin_layout Plain Layout
References
\end_layout

\begin_layout Plain Layout
The list of cited references should appear at the end of the report, ordered
 alphabetically by the surnames of the first authors.
 The default style for references cited in the main text is the Harvard
 (author, date) format.
 When citing a section in a book, please give the relevant page numbers,
 as in 
\begin_inset CommandInset citation
LatexCommand cite
after "p293"
key "budgen"

\end_inset

.
 When citing, where there are either one or two authors, use the names,
 but if there are more than two, give the first one and use 
\begin_inset Quotes eld
\end_inset

et al.
\begin_inset Quotes erd
\end_inset

 as in , except where this would be ambiguous, in which case use all author
 names.
\end_layout

\begin_layout Plain Layout
You need to give all authors' names in each reference.
 Do not use 
\begin_inset Quotes eld
\end_inset

et al.
\begin_inset Quotes erd
\end_inset

 unless there are more than five authors.
 Papers that have not been published should be cited as 
\begin_inset Quotes eld
\end_inset

unpublished
\begin_inset Quotes erd
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "euther"

\end_inset

.
 Papers that have been submitted or accepted for publication should be cited
 as 
\begin_inset Quotes eld
\end_inset

submitted for publication
\begin_inset Quotes erd
\end_inset

 as in 
\begin_inset CommandInset citation
LatexCommand cite
key "futher"

\end_inset

 .
 You can also cite using just the year when the author's name appears in
 the text, as in 
\begin_inset Quotes eld
\end_inset

but according to Futher 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
citeyear{futher}
\end_layout

\end_inset

, we …
\begin_inset Quotes erd
\end_inset

.
 Where an authors has more than one publication in a year, add `a', `b'
 etc.
 after the year.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "library"
options "bibtotoc,default"

\end_inset


\end_layout

\end_body
\end_document
